{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing exercises: find 10 papers that have applied kNN, Decision Tree and Naive Bayes to solve their problems. For each paper, explain the problems they are solving, the techniques and the data that were used in the paper. Write this in your Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) **Forecasting copper prices by decision tree learning**\n",
    "\n",
    "In this paper, a machine-learning algorithm based on decision tree has been implemented to predict the copper prices. The result is rather satisfying by able to predict the future copper prices accurately with an error below 5%. For data preparation, prices of all others commodities such as gold, silver, crude oil and etc have been collected, and the correlation between copper and all other commodities have been analysed to determine the features for training. From the correlation studies, the prices of crude oil, gold , silver and other commodities are highly correlated with copper. Hence, those variables are used as input data in a form of 1x8 array. There are two important parameter, G & D used in this decision tree model, where D = price of other correlated variables on past D days used AS INPUT, and G is the G-th day after tomorrow for the prediction. The model has been tested by using different D & G parameters, and the results were good where the RMSE are < 5% on average.\n",
    "\n",
    "Reference: \n",
    "\n",
    "*Chang Liu, Zhenhua Hu, Yan Li, Shaojun Liu, Forecasting copper prices by decision tree learning, Resources Policy, Volume 52, 2017, Pages 427-434, ISSN 0301-4207\n",
    "Ömer Faruk Arar, Kürşat Ayan, A feature dependent Naive Bayes approach and its application to the software defect prediction problem, Applied Soft Computing, Volume 59, 2017, Pages 197-209, ISSN 1568-4946*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) **A feature dependent Naive Bayes approach and its application to the software defect prediction problem**\n",
    "\n",
    "In this paper, a Feature Dependent Naive Bayes (FDNB) classification has been proposed to software defect prediction problem by using NASA PROMISE datasets. Each dataset consists of multiple software modules, and each modules has various code metrics to be used as input for the classifier. The metrics that have been used are Line of Code ( LoC ), McCabe, Halstead and others. Feature selection have been implemented to filter out metrics that are not significant for prediction of software defect. Correlation-based selection filter method was used and a heuristic search algorithm has been implemented to extract the best feature subsets. The preprocessing of the data was continued by doing normalization, discretization to improve the classifier performance. The discretization is used to split the numerical values of various software metric into categorical values, and used for probability distribution calculation in the training and testing.The last step of the preprocessing is the class distribution balancer. The distribution rebalancing is required due to the fact that non-defective modules outnumbers defective modules in a large extent which will lead to sampling issues. To further improve the performance of the classifier, FDNB has been implemented to ensure the feature independence are truly achieved. It was done by taking probability of occurrence of each feature along with others into account. The performance of FDNB classifier was compared to other types of Naive Bayes classifier and the result of FDNB is slightly better where fewer false alarm reported. Another comparison has been made by using all data in the preprocessing instead of training set only. The results showed that using all data in preprocessing degrade the performance and provide misleading results.\n",
    "\n",
    "Reference: \n",
    "\n",
    "*K. A. Omer Faruk Arar, \"A feature dependent Naive Bayes approach and its application to the software defect prediction problem,\" Applied Soft Computing, vol. 59, pp. 197-209, 2017.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) **A Naive SVM-KNN based stock market trend reversal analysis for Indian benchmark indices**\n",
    "\n",
    "In this paper, a hybridized framework of Support Vector Machine ( SVM ) with K-Nearest Neighbor approach has been proposed to perform Indian stock market indices prediction. The goal of the study is to predict the closing price, volatility and momentum of stock market based on available data. The dataset used in this study are BSE SENSEX and CNX Nifty, where both of them are stock exchange in Asia. The first step of the preprocessing will be time series dataset generation, which consists of stock opening, stock lower, stock higher and stock closing price for any day. A new label has been introduced to identify the volatility or momentum of the stock, which is calculated using difference of closing price on current and previous day. Next, various stock technical indicators such as RSI, ATR, Williams%R, MA were included as part of the input data. The model works in three phases, in phase 1, the dataset was updated using the preprocessing method mentioned earlier. Next in phase 2, datasets is divided into two parts and training was done using SVM classifier. In phase 3, data is classified using SVM and K nearest neighbors is searched to identify the distance. The performance of hybrid KNN + SVM model has been compared to FLIT2FNS and CEFLANN. The performance of hybrid KNN + SVM model is better than proved that it is useful not only to predict closing price, but also able to identify volatility and stock momentum.\n",
    "\n",
    "Reference:\n",
    "\n",
    "*Rudra Kalyan Nayak, Debahuti Mishra, Amiya Kumar Rath, A Naïve SVM-KNN based stock market trend reversal analysis for Indian benchmark indices, Applied Soft Computing, Volume 35, 2015, Pages 670-680, ISSN 1568-4946*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) **Prediction of Heart Disease Based on Decision Trees**\n",
    "\n",
    "Decision tree is a machine learning algorithm that uses a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is commonly used in clinical decisoin support system, to assist doctor on the premilinary diagnosis on patients. In this studies, a heart disease prediction model has been built based on decision tree algorithm. Currently, heart disease is still unable to observed from naked eyes and it can happend anytime and anywhere without any symptoms. The model will be able to predict the likeliness of patients who might suffer heart disease, basead on input data consists of age, gender, chest, pain, resting blood pressure in mmHg, serum cholesterol in mg/d, hereditary, fasting blood pressure in mg/dl, thal and smoking habits.\n",
    "\n",
    "Reference:\n",
    "\n",
    "*Lakshmishree, J., & Paramesha, K. (2017, May). Prediction of Heart Disease Based on Decision Trees. International Journal for Research in Applied Science & Engineering Technology (IJRASET) (Volume 5 Issue V).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) **Application of String Vector based K Nearest Neighbor to Content based Segmentation of each News Article**\n",
    "\n",
    "Text segmentation is a technique to sectioning a long content into subtexts dependent on its substance, so that the articles can be categorized easily. In this studies, a string vector based KNN has been proposed to perform text segmentation. The sample paragraphs have been pre-processing by labeled with boundary domain by domain, and encoded into string vectors. By going through the articles, a list of adjacent paragraph pairs is generated which is by default assumed to be tagged with its own domain. Similarities of the extracted pairs with sample in corresponding domain will be computed. The label of the paris is decided by voting ones of the nearest neighbors. \n",
    "\n",
    "Reference:\n",
    "\n",
    "*Taeho, J. (2019, May). Application of String Vector based K Nearest Neighbor to Content based Segmentation of each News Article. School of Game Hongik University Sejong, South Korea (Vol. 2 No. 1). ICAEIC.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) **The Application of Improved Decision Tree Algorithm in Data Mining of Employment Rate: Evidence from China**\n",
    "\n",
    "Currently,one of the key assesment for succesfulness of  higher education institute is their student's employment rate. In this paper, an improved Decision Tree algorithm has been proposed for forecasting of student's employment rate and also deep-seated data mining of the teaching information. Students data are extracted from scholl management system and information such as gender, agent, department, scholarship and etc have been used as input attributes. The predicted attribute / output is the Employed status, a Boolean flag. The proposed improvement is able to overcame shortcomings or IF3, where the time taken to build the model is lesser, and also improved ID3 decision tree algorithm is also able to perform multi-value attribute selection. The improvement on the algorithm is focus on two area: adding new attribute measure when building the model. Attribute that has higher attribute measure is more significant in the classification. Another new attribute introduced is the rate of information gain or GainRatio, where selection of attribute should also pick the attribute with highest GainRatio.\n",
    "\n",
    "Reference\n",
    "\n",
    "*Y. Shao, Q. Chen and W. Yin, \"The Application of Improved Decision Tree Algorithm in Data Mining of Employment Rate: Evidence from China,\" 2009 First International Workshop on Database Technology and Applications, Wuhan, Hubei, 2009, pp. 202-205.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) **A New Approach for Off-Line Handwritten Arabic Word Recognition Using KNN Classifier**\n",
    "\n",
    "Arabic handwriting is considered one of the hardest language to be recognized by machine due to its similarity with other lanaguges. In order to resolve this, this studies proposed an offline system for Arabic Handwriting Recognition using KNN classifier. Dataset from IFN/ENIT which consists of 32492 handwritten Arabic words by more than 1000 writers was used and the result is satisfying. The recognition is done in three stages: pre-processing, feature extractyion and classification. The pre-processing described in the paper are estimation of the baseline and normalization to remove the variations of the handwritten images for consistent results. Feature extraction is done by remove the redundanacy of the data. Overlapping block is applied by dividing the word image into overlappinmg blocks where the size of block is 12pixels and length of overlapping is 2pixels. lastly, the dataset is splitted into test and training. The proposed algorithm is able to achieve a prediction rate of 76.04%.\n",
    "\n",
    "Reference\n",
    "\n",
    "*J. H. AlKhateeb, F. Khelifi, J. Jiang and S. S. Ipson, \"A new approach for off-line handwritten Arabic word recognition using KNN classifier,\" 2009 IEEE International Conference on Signal and Image Processing Applications, Kuala Lumpur, 2009, pp. 191-194.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) **Application of the Naive Bayes Method to a Decision Support System to provide Discounts (Case Study: PT. Bina Usaha Teknik)**\n",
    "\n",
    "This paper proposed a decision support system in granting discounts for multi-criteria system using Naive Bayes Classifier. The criteris include the purchase of some items, the status of the product, the big day, price ranges. The dataset used are real trading data from PT Bina Usaha Teknik company which is active in general trading of engineering tools. The proposed system was used to simplify large amount of information to help right decision making. The system was developed with RAD ( Rapid Application seeking Development) using UML (Unified Modeling Language).   The Naive Bayes classification will first determine the criteria and determine the class, and the probabaility of each class will be calculated. It can be said that the system succeeded to provide alternative in calculating price discounts recommendations based on the final probability by any combination of variables/criteria.\n",
    "\n",
    "Reference:\n",
    "\n",
    "*F. Burdi, A. H. Setianingrum and N. Hakiem, \"Application of the Naive Bayes Method to a Decision Support System to Provide Discounts (Case Study: PT. Bina Usaha Teknik),\" 2016 6th International Conference on Information and Communication Technology for The Muslim World (ICT4M), Jakarta, 2016, pp. 281-285.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) **MFZ-KNN-A Modified Fuzzy Based K Nearest Neighbor Algorithm**\n",
    "(Case Study:standard UCI data set-Wine)\n",
    "\n",
    "A new clustering technique using improved fuzzy base KNN algorithm MFZ-KNN has been proposed to determine the fuzzy areas in the dataset prior to classification using FCM algorithm.One of the common problem faced in conventional KNN is that, each of the sample data is given equal importance. There is no futher information to indicate the strengh of membership in that class.\n",
    "The proposed MFZ-KNN algorithm has two different stage: data preprocessing and classification process. In data preprocessing, the number of clusters will be computed, and the training data will be set into fuzzy clusters using fuzzy c-mean algorithm. The last step of the preprocessing is to determine the centroid of each cluster and membership between centroid and data point.\n",
    "Next, the classification will be done by using KNN. The results prove that it is better than both conventional KNN and fuzzy KNN in terms of accuracy and time.\n",
    "\n",
    "Reference\n",
    "\n",
    "*Taneja, Shweta & Gupta, Charu & Aggarwal, Sakshi & Jindal, Veni. (2015). MFZ-KNN-A modified fuzzy based K nearest neighbor algorithm. Proceedings - 2015 International Conference on Cognitive Computing and Information Processing, CCIP 2015. 10.1109/CCIP.2015.7100689.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) **Eager Decision Tree** (Case Study: PlayTennis)\n",
    "\n",
    "In this paper, a new novel algorithm 'Eager Decision Tree' has been proposed. The new algorithm will consists of single prediction model at the time of training which all possibilites of unknown attributes values will be considered. By doing this, the problems of handing unknown values in testing data will be eliminated. In previous work, Lazy Decision Tree has been introduced where the classification tree is contructed at the prediction time based on availability of test example attribute values. However, in the newly proposed \"Eager Decision Tree\", an additional branch called \"UAT-Unknown at Test\" is constructed in additional to the other branches/ nodes. If any missing values is identifies, the algorithm will select UAT branches and moving to its child.\n",
    "\n",
    "Reference:\n",
    "*S. S. Gavankar and S. D. Sawarkar, \"Eager decision tree,\" 2017 2nd International Conference for Convergence in Technology (I2CT), Mumbai, 2017, pp. 837-840.\n",
    "doi: 10.1109/I2CT.2017.8226246*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
